{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql import Row\n",
    "import pyspark\n",
    "import numpy as np\n",
    "from pyspark.sql.functions import col, explode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df=pd.read_csv(\"data/ratings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df=pd.read_csv(\"data/updated_movies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_movie_df=movies_df[((movies_df['avg_user_rating']>=4)& \n",
    "                                   (movies_df['year']>=1980))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ratings_df=ratings_df.merge(samples_movie_df,on=\"movieId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movieId             2595527\n",
       "title_x             2595527\n",
       "genres_x            2595527\n",
       "userId              2595527\n",
       "rating              2595527\n",
       "rating_timestamp    2595527\n",
       "tag                  108644\n",
       "tags_timestamp       108644\n",
       "title_y             2595527\n",
       "genres_y            2595527\n",
       "avg_user_rating     2595527\n",
       "year                2595527\n",
       "comb                2595527\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_ratings_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initiate Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scSpark = SparkSession \\\n",
    "        .builder \\\n",
    "        .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data into spark dataframe\n",
    "ratings = scSpark.read\\\n",
    "            .option(\"inferSchema\", \"true\")\\\n",
    "            .csv(\"data/ratings.csv\", header=True, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- timestamp: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check dataframe schema\n",
    "ratings.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating|timestamp |\n",
      "+------+-------+------+----------+\n",
      "|1     |296    |5.0   |1147880044|\n",
      "|1     |306    |3.5   |1147868817|\n",
      "|1     |307    |5.0   |1147868828|\n",
      "|1     |665    |5.0   |1147878820|\n",
      "|1     |899    |3.5   |1147868510|\n",
      "|1     |1088   |4.0   |1147868495|\n",
      "|1     |1175   |3.5   |1147868826|\n",
      "|1     |1217   |3.5   |1147878326|\n",
      "|1     |1237   |5.0   |1147868839|\n",
      "|1     |1250   |4.0   |1147868414|\n",
      "|1     |1260   |3.5   |1147877857|\n",
      "|1     |1653   |4.0   |1147868097|\n",
      "|1     |2011   |2.5   |1147868079|\n",
      "|1     |2012   |2.5   |1147868068|\n",
      "|1     |2068   |2.5   |1147869044|\n",
      "|1     |2161   |3.5   |1147868609|\n",
      "|1     |2351   |4.5   |1147877957|\n",
      "|1     |2573   |4.0   |1147878923|\n",
      "|1     |2632   |5.0   |1147878248|\n",
      "|1     |2692   |5.0   |1147869100|\n",
      "+------+-------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Check for first 20 records\n",
    "ratings.show(20,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop timestamp\n",
    "ratings = ratings.drop(*['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+\n",
      "|userId|movieId|rating|\n",
      "+------+-------+------+\n",
      "|     1|    296|   5.0|\n",
      "|     1|    306|   3.5|\n",
      "|     1|    307|   5.0|\n",
      "|     1|    665|   5.0|\n",
      "|     1|    899|   3.5|\n",
      "|     1|   1088|   4.0|\n",
      "|     1|   1175|   3.5|\n",
      "|     1|   1217|   3.5|\n",
      "|     1|   1237|   5.0|\n",
      "|     1|   1250|   4.0|\n",
      "|     1|   1260|   3.5|\n",
      "|     1|   1653|   4.0|\n",
      "|     1|   2011|   2.5|\n",
      "|     1|   2012|   2.5|\n",
      "|     1|   2068|   2.5|\n",
      "|     1|   2161|   3.5|\n",
      "|     1|   2351|   4.5|\n",
      "|     1|   2573|   4.0|\n",
      "|     1|   2632|   5.0|\n",
      "|     1|   2692|   5.0|\n",
      "+------+-------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000095"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the number of records in dataframe\n",
    "ratings.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read movies data csv created in ETL into dataframe\n",
    "movies_df=pd.read_csv(\"data/updated_movies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>avg_user_rating</th>\n",
       "      <th>year</th>\n",
       "      <th>comb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Persuasion (1995)</td>\n",
       "      <td>Drama Romance</td>\n",
       "      <td>4.030000</td>\n",
       "      <td>1995</td>\n",
       "      <td>Drama Romance 4.03 1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47</td>\n",
       "      <td>Seven (a.k.a. Se7en) (1995)</td>\n",
       "      <td>Mystery Thriller</td>\n",
       "      <td>4.079166</td>\n",
       "      <td>1995</td>\n",
       "      <td>Mystery Thriller 4.0792 1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>50</td>\n",
       "      <td>Usual Suspects, The (1995)</td>\n",
       "      <td>Crime Mystery Thriller</td>\n",
       "      <td>4.284353</td>\n",
       "      <td>1995</td>\n",
       "      <td>Crime Mystery Thriller 4.2844 1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>110</td>\n",
       "      <td>Braveheart (1995)</td>\n",
       "      <td>Action Drama War</td>\n",
       "      <td>4.002273</td>\n",
       "      <td>1995</td>\n",
       "      <td>Action Drama War 4.0023 1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>162</td>\n",
       "      <td>Crumb (1994)</td>\n",
       "      <td>Documentary</td>\n",
       "      <td>4.008077</td>\n",
       "      <td>1994</td>\n",
       "      <td>Documentary 4.0081 1994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     movieId                        title                  genres  \\\n",
       "27        28            Persuasion (1995)           Drama Romance   \n",
       "46        47  Seven (a.k.a. Se7en) (1995)        Mystery Thriller   \n",
       "49        50   Usual Suspects, The (1995)  Crime Mystery Thriller   \n",
       "108      110            Braveheart (1995)        Action Drama War   \n",
       "160      162                 Crumb (1994)             Documentary   \n",
       "\n",
       "     avg_user_rating  year                                comb  \n",
       "27          4.030000  1995             Drama Romance 4.03 1995  \n",
       "46          4.079166  1995        Mystery Thriller 4.0792 1995  \n",
       "49          4.284353  1995  Crime Mystery Thriller 4.2844 1995  \n",
       "108         4.002273  1995        Action Drama War 4.0023 1995  \n",
       "160         4.008077  1994             Documentary 4.0081 1994  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_movie_df=movies_df[((movies_df['avg_user_rating']>=4)& \n",
    "                                   (movies_df['year']>=1980))]\n",
    "#df_inner = df1.join(df2, on=['Roll_No'], how='inner')\n",
    "samples_movie_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute '_jdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-e951bf78d349>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msample_ratings\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mratings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples_movie_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'movieId'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'inner'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pyspark\\sql\\dataframe.py\u001b[0m in \u001b[0;36mjoin\u001b[1;34m(self, other, on, how)\u001b[0m\n\u001b[0;32m   1146\u001b[0m                 \u001b[0mon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jseq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1147\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"how should be basestring\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1148\u001b[1;33m             \u001b[0mjdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1149\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5272\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5273\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5274\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5276\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute '_jdf'"
     ]
    }
   ],
   "source": [
    "sample_ratings=ratings.join(samples_movie_df,on=['movieId'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ratings.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25273"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reducing the size of dataset initially to train model\n",
    "sample_ratings_df = ratings.sample(fraction=0.001, seed=42)\n",
    "sample_ratings_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+\n",
      "|userId|movieId|rating|\n",
      "+------+-------+------+\n",
      "|    58|    527|   5.0|\n",
      "|    59|    249|   3.5|\n",
      "|    59|   3996|   4.5|\n",
      "|    62|  54286|   4.0|\n",
      "|    70|   5445|   4.0|\n",
      "|    72|   2405|   2.0|\n",
      "|    72|   3917|   4.0|\n",
      "|    80|    891|   2.0|\n",
      "|    80|   3174|   3.0|\n",
      "|    84|  40629|   3.5|\n",
      "|    98|   4912|   4.0|\n",
      "|   101|   1569|   3.0|\n",
      "|   114|  79132|   5.0|\n",
      "|   117|   4447|   5.0|\n",
      "|   119|  79132|   1.0|\n",
      "|   120|   2058|   5.0|\n",
      "|   130|      6|   3.0|\n",
      "|   142|   1247|   4.5|\n",
      "|   145|   1194|   5.0|\n",
      "|   146|  69757|   3.0|\n",
      "+------+-------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_ratings_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = pyspark.sql.SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"spark_lens\") \\\n",
    "    .master(\"local[2]\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|nulls|\n",
      "+-----+\n",
      "|    0|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Register temp table.\n",
    "#checking for nulls \n",
    "sample_ratings_df.registerTempTable('rating')\n",
    "# Query table for number of nulls.\n",
    "spark.sql('''\n",
    "    SELECT COUNT(rating) AS nulls\n",
    "    FROM rating \n",
    "    WHERE rating=null\n",
    "''').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split Training and Test data\n",
    "training, test = sample_ratings_df.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20276"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.ml.recommendation.ALS"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create Basic Model\n",
    "als = ALS(nonnegative=True, implicitPrefs=False, coldStartStrategy=\"drop\")\\\n",
    ".setMaxIter(5)\\\n",
    ".setRegParam(0.01)\\\n",
    ".setUserCol(\"userId\")\\\n",
    ".setItemCol(\"movieId\")\\\n",
    ".setRatingCol(\"rating\")\\\n",
    "\n",
    "\n",
    "# Confirm that a model called \"als\" was created\n",
    "type(als)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"alpha: alpha for implicit preference (default: 1.0)\\nblockSize: block size for stacking input data in matrices. Data is stacked within partitions. If block size is more than remaining data in a partition then it is adjusted to the size of this data. (default: 4096)\\ncheckpointInterval: set checkpoint interval (>= 1) or disable checkpoint (-1). E.g. 10 means that the cache will get checkpointed every 10 iterations. Note: this setting will be ignored if the checkpoint directory is not set in the SparkContext. (default: 10)\\ncoldStartStrategy: strategy for dealing with unknown or new users/items at prediction time. This may be useful in cross-validation or production scenarios, for handling user/item ids the model has not seen in the training data. Supported values: 'nan', 'drop'. (default: nan, current: drop)\\nfinalStorageLevel: StorageLevel for ALS model factors. (default: MEMORY_AND_DISK)\\nimplicitPrefs: whether to use implicit preference (default: False, current: False)\\nintermediateStorageLevel: StorageLevel for intermediate datasets. Cannot be 'NONE'. (default: MEMORY_AND_DISK)\\nitemCol: column name for item ids. Ids must be within the integer value range. (default: item, current: movieId)\\nmaxIter: max number of iterations (>= 0). (default: 10, current: 5)\\nnonnegative: whether to use nonnegative constraint for least squares (default: False, current: True)\\nnumItemBlocks: number of item blocks (default: 10)\\nnumUserBlocks: number of user blocks (default: 10)\\npredictionCol: prediction column name. (default: prediction)\\nrank: rank of the factorization (default: 10)\\nratingCol: column name for ratings (default: rating, current: rating)\\nregParam: regularization parameter (>= 0). (default: 0.1, current: 0.01)\\nseed: random seed. (default: -1780186684048401868)\\nuserCol: column name for user ids. Ids must be within the integer value range. (default: user, current: userId)\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "als.explainParams()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num models to be tested:  16\n"
     ]
    }
   ],
   "source": [
    "# Import the requisite items\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "# Add hyperparameters and their respective values to param_grid\n",
    "param_grid = ParamGridBuilder() \\\n",
    "            .addGrid(als.rank, [10, 50, 100, 150]) \\\n",
    "            .addGrid(als.regParam, [.01, .05, .1, .15]) \\\n",
    "            .build()\n",
    "           \n",
    "# Define evaluator as RMSE and print length of evaluator\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\") \n",
    "print (\"Num models to be tested: \", len(param_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrossValidator_6ee5fd121342\n"
     ]
    }
   ],
   "source": [
    "# Build cross validation using CrossValidator\n",
    "cv = CrossValidator(estimator=als, estimatorParamMaps=param_grid, evaluator=evaluator, numFolds=5)\n",
    "\n",
    "# Confirm cv was built\n",
    "print(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit cross validator to the 'train' dataset\n",
    "model = cv.fit(training)\n",
    "\n",
    "#Extract best model from the cv model above\n",
    "alsmodel = model.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.ml.recommendation.ALSModel'>\n",
      "**Best Model**\n",
      "  Rank: 150\n",
      "  MaxIter: 5\n",
      "  RegParam: 0.01\n"
     ]
    }
   ],
   "source": [
    "# Print best_model\n",
    "print(type(alsmodel))\n",
    "\n",
    "# Complete the code below to extract the ALS model parameters\n",
    "print(\"**Best Model**\")\n",
    "\n",
    "# # Print \"Rank\"\n",
    "print(\"  Rank:\", alsmodel._java_obj.parent().getRank())\n",
    "\n",
    "# Print \"MaxIter\"\n",
    "print(\"  MaxIter:\", alsmodel._java_obj.parent().getMaxIter())\n",
    "\n",
    "# Print \"RegParam\"\n",
    "print(\"  RegParam:\", alsmodel._java_obj.parent().getRegParam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0734268767244757\n"
     ]
    }
   ],
   "source": [
    "# View the predictions\n",
    "test_predictions = alsmodel.transform(test)\n",
    "RMSE = evaluator.evaluate(test_predictions)\n",
    "print(RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating|prediction|\n",
      "+------+-------+------+----------+\n",
      "|154155|    471|   1.0|0.72159994|\n",
      "|117811|   1088|   1.0| 2.1162229|\n",
      "| 93792|   1088|   2.5|  2.684103|\n",
      "| 78266|   1580|   3.0| 2.7079184|\n",
      "| 63752|   1580|   3.5|  3.931393|\n",
      "|114620|   1580|   2.0| 2.0368276|\n",
      "| 84238|   2366|   2.5|  2.642948|\n",
      "|157814|   3175|   3.5| 1.8547676|\n",
      "|117149|   6620|   4.5| 1.7417858|\n",
      "| 23704|  44022|   4.0| 1.0748026|\n",
      "|107576|  96488|   3.5| 0.5121748|\n",
      "|120611|   1084|   3.5| 2.3217304|\n",
      "|  8528|   1127|   2.0| 2.1911337|\n",
      "|134837|   2387|   3.0| 0.7957061|\n",
      "| 82177|   2580|   4.0| 1.9651451|\n",
      "|  5615|  48780|   4.0| 2.2055964|\n",
      "|148362|  48780|   3.5| 1.0791944|\n",
      "| 78229|  69481|   2.0| 1.8774968|\n",
      "|141420| 196889|   3.0| 1.3115584|\n",
      "| 51061|   1270|   3.0| 3.0732176|\n",
      "+------+-------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|userId|     recommendations|\n",
      "+------+--------------------+\n",
      "|  7340|[[661, 1.999686],...|\n",
      "| 30970|[[2424, 2.9995534...|\n",
      "| 35820|[[953, 3.9996536]...|\n",
      "| 56110|[[2959, 4.9993634...|\n",
      "| 68610|[[5060, 4.9995394...|\n",
      "| 95080|[[1208, 4.0737495...|\n",
      "|108460|[[107, 4.999004],...|\n",
      "|160820|[[2959, 5.089485]...|\n",
      "| 46521|[[1207, 3.9996793...|\n",
      "| 47501|[[1387, 4.932577]...|\n",
      "| 57201|[[37729, 2.999528...|\n",
      "| 74251|[[1220, 5.6360917...|\n",
      "| 83861|[[223, 3.0247295]...|\n",
      "|103011|[[1213, 3.5473666...|\n",
      "|112971|[[3000, 3.2555804...|\n",
      "|124861|[[34, 3.9995875],...|\n",
      "|126191|[[919, 1.4998838]...|\n",
      "|128131|[[316, 2.9996943]...|\n",
      "|131811|[[1584, 3.3589978...|\n",
      "|145011|[[6539, 2.999699]...|\n",
      "+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nrecoomendations=alsmodel.recommendForAllUsers(5)\n",
    "nrecoomendations.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+---------+\n",
      "|userId|movieId|   rating|\n",
      "+------+-------+---------+\n",
      "|  7340|    661| 1.999686|\n",
      "|  7340|    527|1.7850212|\n",
      "|  7340|   1387|1.7770323|\n",
      "|  7340|   1291|1.7741535|\n",
      "|  7340|   1220|1.7616001|\n",
      "| 30970|   2424|2.9995534|\n",
      "| 30970|    318|2.7798882|\n",
      "| 30970|   1193| 2.680576|\n",
      "| 30970|  68358|2.6383505|\n",
      "| 30970|    527|2.6167846|\n",
      "+------+-------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nrecoomendations = nrecoomendations\\\n",
    "    .withColumn(\"rec_exp\", explode(\"recommendations\"))\\\n",
    "    .select('userId', col(\"rec_exp.movieId\"), col(\"rec_exp.rating\"))\n",
    "\n",
    "nrecoomendations.limit(10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data into spark dataframe\n",
    "movies = scSpark.read\\\n",
    "            .option(\"inferSchema\", \"true\")\\\n",
    "            .csv(\"data/movies.csv\", header=True, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------+--------------------+--------------------+\n",
      "|movieId|userId|rating|               title|              genres|\n",
      "+-------+------+------+--------------------+--------------------+\n",
      "|    946|  7340|   5.0|To Be or Not to B...|    Comedy|Drama|War|\n",
      "|   3996|  7340|   5.0|Crouching Tiger, ...|Action|Drama|Romance|\n",
      "|   1221|  7340|   5.0|Godfather: Part I...|         Crime|Drama|\n",
      "|    750|  7340|   5.0|Dr. Strangelove o...|          Comedy|War|\n",
      "|   1232|  7340|   5.0|      Stalker (1979)|Drama|Mystery|Sci-Fi|\n",
      "|    904|  7340|   5.0|  Rear Window (1954)|    Mystery|Thriller|\n",
      "|   1265|  7340|   5.0|Groundhog Day (1993)|Comedy|Fantasy|Ro...|\n",
      "|    926|  7340|   5.0|All About Eve (1950)|               Drama|\n",
      "|   2019|  7340|   5.0|Seven Samurai (Sh...|Action|Adventure|...|\n",
      "|   2599|  7340|   5.0|     Election (1999)|              Comedy|\n",
      "+-------+------+------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings.join(movies, on='movieId').filter('userId = 7340').sort('rating', ascending=False).limit(10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+---------+--------------------+--------------------+\n",
      "|movieId|userId|   rating|               title|              genres|\n",
      "+-------+------+---------+--------------------+--------------------+\n",
      "|    661|  7340| 1.999686|James and the Gia...|Adventure|Animati...|\n",
      "|    527|  7340|1.7850212|Schindler's List ...|           Drama|War|\n",
      "|   1387|  7340|1.7770323|         Jaws (1975)|       Action|Horror|\n",
      "|   1291|  7340|1.7741535|Indiana Jones and...|    Action|Adventure|\n",
      "|   1220|  7340|1.7616001|Blues Brothers, T...|Action|Comedy|Mus...|\n",
      "+-------+------+---------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nrecoomendations.join(movies, on='movieId').filter('userId=7340').sort('rating', ascending=False).limit(10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exporting model into a .pickl file for use in front-end\n",
    "nrecoomendations.toPandas().to_csv(\"collab_filter_recommendations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.toPandas().to_csv(\"collab_filter_movies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
